{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfAiz0z1qGWT"
      },
      "source": [
        "**Import Libraries and Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvD4tD8EqKsM",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets scikit-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load datasets\n",
        "src_llm_train = pd.read_csv('src_llm_train.csv')\n",
        "src_llm_validation = pd.read_csv('src_llm_validation.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HP3k8Pkrepd"
      },
      "source": [
        "**Tokenise the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCmoY2vCrjBx"
      },
      "outputs": [],
      "source": [
        "# Set seeds before initializing anything that uses randomness\n",
        "seed_value = 12345\n",
        "torch.manual_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define a function to tokenize and encode data\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize the articles\n",
        "    tokenized = tokenizer(examples['Article'], padding=\"max_length\", truncation=True)\n",
        "    # Add encoded labels (Solidarity column)\n",
        "    tokenized['label'] = examples['Solidarity']\n",
        "    return tokenized\n",
        "\n",
        "# Convert DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(src_llm_train)\n",
        "val_dataset = Dataset.from_pandas(src_llm_validation)\n",
        "\n",
        "# Apply the preprocessing function\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-bcYeMUtFR5",
        "outputId": "0973f40e-1c54-43b0-dd30-65f91b5e51d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the model for binary classification\n",
        "num_labels = 2\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory\n",
        "    learning_rate=1e-5,              # Learning Rate\n",
        "    lr_scheduler_type='cosine',\n",
        "    num_train_epochs=30,             # Number of training epochs\n",
        "    per_device_train_batch_size=4,   # Batch size for training\n",
        "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
        "    warmup_steps=1000,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\"  # Evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Define accuracy metric for binary classification\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average='binary', zero_division=0)\n",
        "    recall = recall_score(labels, preds, average='binary')\n",
        "    f1 = f1_score(labels, preds, average='binary')\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f8t6ZQ3uFvR"
      },
      "source": [
        "**Training the model and validation results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cdwvvx91uJw4",
        "outputId": "5a41061a-3a00-4c5e-e924-601649bb74b9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1110' max='1110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1110/1110 14:05, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.632300</td>\n",
              "      <td>0.693518</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.704800</td>\n",
              "      <td>0.690844</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.713200</td>\n",
              "      <td>0.686685</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.715200</td>\n",
              "      <td>0.687250</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.673100</td>\n",
              "      <td>0.684631</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.631700</td>\n",
              "      <td>0.678788</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.547619</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.696970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.640800</td>\n",
              "      <td>0.674332</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.704000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.584500</td>\n",
              "      <td>0.664584</td>\n",
              "      <td>0.595506</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.532000</td>\n",
              "      <td>0.655522</td>\n",
              "      <td>0.595506</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.608696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.432000</td>\n",
              "      <td>0.669546</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.609375</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.696429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.400500</td>\n",
              "      <td>0.704902</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.653846</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.459459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.359600</td>\n",
              "      <td>0.672600</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.622222</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.602151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.211700</td>\n",
              "      <td>0.757365</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.763386</td>\n",
              "      <td>0.595506</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.182200</td>\n",
              "      <td>1.096325</td>\n",
              "      <td>0.505618</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.104200</td>\n",
              "      <td>0.817392</td>\n",
              "      <td>0.629213</td>\n",
              "      <td>0.659574</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.652632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.072800</td>\n",
              "      <td>0.923170</td>\n",
              "      <td>0.595506</td>\n",
              "      <td>0.657895</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>0.581395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.048500</td>\n",
              "      <td>1.146374</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.458333</td>\n",
              "      <td>0.536585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>1.191592</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.564706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.012300</td>\n",
              "      <td>1.380002</td>\n",
              "      <td>0.606742</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.606742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>1.659010</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.354167</td>\n",
              "      <td>0.472222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>1.795934</td>\n",
              "      <td>0.539326</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.422535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>1.803273</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.547619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>1.855683</td>\n",
              "      <td>0.640449</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.589744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>1.683826</td>\n",
              "      <td>0.617978</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.645833</td>\n",
              "      <td>0.645833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>1.870334</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.648649</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.564706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>2.394792</td>\n",
              "      <td>0.550562</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.291667</td>\n",
              "      <td>0.411765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>2.125855</td>\n",
              "      <td>0.573034</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.577778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>2.088437</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.593407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>2.135101</td>\n",
              "      <td>0.584270</td>\n",
              "      <td>0.657143</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.554217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='23' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [23/23 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation results: {'eval_loss': 1.8556827306747437, 'eval_accuracy': 0.6404494382022472, 'eval_precision': 0.7666666666666667, 'eval_recall': 0.4791666666666667, 'eval_f1': 0.5897435897435898, 'eval_runtime': 2.8068, 'eval_samples_per_second': 31.708, 'eval_steps_per_second': 8.194, 'epoch': 30.0}\n"
          ]
        }
      ],
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The model to train\n",
        "    args=training_args,                  # Training arguments\n",
        "    train_dataset=train_dataset,         # Training dataset\n",
        "    eval_dataset=val_dataset,            # Validation dataset\n",
        "    compute_metrics=compute_metrics      # Function to compute metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"Validation results:\", eval_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run predictions on test data**"
      ],
      "metadata": {
        "id": "QeBPOP7opQfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best trained model\n",
        "best_checkpoint_path = trainer.state.best_model_checkpoint\n",
        "print(\"Best checkpoint:\", best_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30ExJzUAooMn",
        "outputId": "1e463527-e6f3-4082-a5b5-98e86aaae507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint: ./results/checkpoint-888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './results/checkpoint-888'\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)"
      ],
      "metadata": {
        "id": "GGcRabmNpVrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }"
      ],
      "metadata": {
        "id": "nR27w4tVqfZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_data = pd.read_csv('src_official_test2.csv')\n",
        "test_texts = test_data['Article']  # Replace with your column name containing text data\n",
        "\n",
        "# Create a dataset for the test data\n",
        "test_dataset = TestDataset(\n",
        "    texts=test_texts,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=512  # Adjust max_len according to your needs\n",
        ")"
      ],
      "metadata": {
        "id": "-5HI6vHvqiHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for the test data\n",
        "test_loader = DataLoader(test_dataset, batch_size=4)\n",
        "\n",
        "# Run predictions on the test data\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        predictions.extend(preds.cpu().numpy())"
      ],
      "metadata": {
        "id": "PY-97H3QqpkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['solidarity_predictions'] = predictions"
      ],
      "metadata": {
        "id": "oJg8L1quiRvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.to_csv('src_llm_solidarity_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "8My0S4qdihBo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}