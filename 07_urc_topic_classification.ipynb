{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries and data**\n"
      ],
      "metadata": {
        "id": "8y4gBiV3WWdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load datasets\n",
        "urc_llm_train = pd.read_csv('urc_llm_train.csv')\n",
        "urc_llm_validation = pd.read_csv('urc_llm_validation.csv')"
      ],
      "metadata": {
        "id": "MBLaV5mgWZ30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenise the data**"
      ],
      "metadata": {
        "id": "mTuEcvQcWiE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds before initializing anything that uses randomness\n",
        "seed_value = 12345\n",
        "torch.manual_seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# Initialize BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Initialize LabelEncoder and fit on training data\n",
        "label_encoder = LabelEncoder()\n",
        "urc_llm_train['Category'] = label_encoder.fit_transform(urc_llm_train['Category'])\n",
        "urc_llm_validation['Category'] = label_encoder.transform(urc_llm_validation['Category'])\n",
        "\n",
        "# Define a function to tokenize and encode data\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize the articles\n",
        "    tokenized = tokenizer(examples['Article'], padding=\"max_length\", truncation=True)\n",
        "    # Add encoded labels\n",
        "    tokenized['label'] = examples['Category']\n",
        "    return tokenized\n",
        "\n",
        "# Convert DataFrames to Hugging Face Datasets\n",
        "train_dataset = Dataset.from_pandas(urc_llm_train)\n",
        "val_dataset = Dataset.from_pandas(urc_llm_validation)\n",
        "\n",
        "# Apply the preprocessing function\n",
        "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])"
      ],
      "metadata": {
        "id": "3zpn8zRNWl56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "num_labels = len(label_encoder.classes_)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory\n",
        "    learning_rate=2e-5,              # Learning Rate\n",
        "    lr_scheduler_type='cosine',\n",
        "    num_train_epochs=40,             # Number of training epochs\n",
        "    per_device_train_batch_size=4,   # Batch size for training\n",
        "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
        "    warmup_steps=1000,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end = True,\n",
        "    metric_for_best_model = \"accuracy\" # Evaluate after each epoch\n",
        ")\n",
        "\n",
        "# Define accuracy metric\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "    precision = precision_score(labels, preds, average='weighted', zero_division = 0)\n",
        "    recall = recall_score(labels, preds, average='weighted')\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\":f1}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmY301TZWz9R",
        "outputId": "79a6bdec-266e-4af4-801b-85d05870b1cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model and validation results**"
      ],
      "metadata": {
        "id": "SGiZSQHdXAFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # The model to train\n",
        "    args=training_args,                  # Training arguments\n",
        "    train_dataset=train_dataset,         # Training dataset\n",
        "    eval_dataset=val_dataset,            # Validation dataset\n",
        "    compute_metrics=compute_metrics      # Function to compute metrics\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(\"Validation results:\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qq7qUgCnXBwF",
        "outputId": "349cea4c-b8dc-4467-aa7c-5bd459797a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1320/1320 19:14, Epoch 40/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.446900</td>\n",
              "      <td>1.443348</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.120908</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.135232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.464200</td>\n",
              "      <td>1.399864</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.130159</td>\n",
              "      <td>0.261905</td>\n",
              "      <td>0.154330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.373200</td>\n",
              "      <td>1.361740</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.254329</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.300909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.278600</td>\n",
              "      <td>1.348080</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.288946</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.274718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.252900</td>\n",
              "      <td>1.350803</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.381746</td>\n",
              "      <td>0.380952</td>\n",
              "      <td>0.293104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.172300</td>\n",
              "      <td>1.304049</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.378988</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.351925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.065900</td>\n",
              "      <td>1.280679</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.371076</td>\n",
              "      <td>0.392857</td>\n",
              "      <td>0.321946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.035400</td>\n",
              "      <td>1.240393</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.364582</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.366375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.859000</td>\n",
              "      <td>1.226970</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.393316</td>\n",
              "      <td>0.476190</td>\n",
              "      <td>0.413868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.889600</td>\n",
              "      <td>1.195103</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.404320</td>\n",
              "      <td>0.511905</td>\n",
              "      <td>0.440677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.636300</td>\n",
              "      <td>1.186859</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.414042</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.451687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.699400</td>\n",
              "      <td>1.149087</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.420330</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.464083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.650200</td>\n",
              "      <td>1.142126</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.410237</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.462613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.511100</td>\n",
              "      <td>1.136879</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.575695</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.539857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.487000</td>\n",
              "      <td>1.256837</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.701460</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.537884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.411400</td>\n",
              "      <td>1.127189</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.544763</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.548139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>1.151792</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.476657</td>\n",
              "      <td>0.535714</td>\n",
              "      <td>0.493162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.204900</td>\n",
              "      <td>1.209407</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.624620</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.592806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.156900</td>\n",
              "      <td>1.308540</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.576426</td>\n",
              "      <td>0.607143</td>\n",
              "      <td>0.569770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.095900</td>\n",
              "      <td>1.361002</td>\n",
              "      <td>0.630952</td>\n",
              "      <td>0.687893</td>\n",
              "      <td>0.630952</td>\n",
              "      <td>0.581629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.057500</td>\n",
              "      <td>1.440363</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.581933</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.580000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.026900</td>\n",
              "      <td>1.638519</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.712963</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.612215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.012700</td>\n",
              "      <td>1.594928</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.620899</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.603832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>1.782595</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.605373</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.596774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.005700</td>\n",
              "      <td>1.804703</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.630466</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.620278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>1.882527</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.613138</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.596812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>1.933530</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.613138</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.596812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.002900</td>\n",
              "      <td>1.963445</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.639262</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.612942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.002500</td>\n",
              "      <td>2.013563</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>2.038305</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.001800</td>\n",
              "      <td>2.084297</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.613138</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.596812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.001900</td>\n",
              "      <td>2.107931</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>2.133756</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.654932</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.629923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>2.158583</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.644372</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.629363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.001400</td>\n",
              "      <td>2.173695</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.644372</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.629363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>2.194644</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.644372</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.629363</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>2.206703</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.001300</td>\n",
              "      <td>2.208699</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.001100</td>\n",
              "      <td>2.209138</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>2.209249</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.629403</td>\n",
              "      <td>0.654762</td>\n",
              "      <td>0.613445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='21' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation results: {'eval_loss': 2.133755922317505, 'eval_accuracy': 0.6666666666666666, 'eval_precision': 0.6549321117335823, 'eval_recall': 0.6666666666666666, 'eval_f1': 0.6299230614112646, 'eval_runtime': 2.7519, 'eval_samples_per_second': 30.524, 'eval_steps_per_second': 7.631, 'epoch': 40.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run predictions on test data**"
      ],
      "metadata": {
        "id": "4fmDU4E050J-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best trained model\n",
        "best_checkpoint_path = trainer.state.best_model_checkpoint\n",
        "print(\"Best checkpoint:\", best_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8Zn7nAx53EJ",
        "outputId": "1063b215-7dfa-4103-91d7-31039f149182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best checkpoint: ./results/checkpoint-1089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = './results/checkpoint-1089'\n",
        "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)"
      ],
      "metadata": {
        "id": "ZUH2cTKT6CZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer, max_len):\n",
        "        self.texts = texts.tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten()\n",
        "        }"
      ],
      "metadata": {
        "id": "AIVfA0AH6GTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_data = pd.read_csv('urc_official_test.csv')\n",
        "test_texts = test_data['Article']\n",
        "\n",
        "# Create a dataset for the test data\n",
        "test_dataset = TestDataset(\n",
        "    texts=test_texts,\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=512\n",
        ")"
      ],
      "metadata": {
        "id": "bjQnGf336KNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for the test data\n",
        "test_loader = DataLoader(test_dataset, batch_size=4)\n",
        "\n",
        "# Run predictions on the test data\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1)\n",
        "        predictions.extend(preds.cpu().numpy())"
      ],
      "metadata": {
        "id": "9v78GR196Tba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['category_predictions'] = predictions"
      ],
      "metadata": {
        "id": "xA2Q34Td6jr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.to_csv('urc_llm_tc_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "5mu8Vm6uCnFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the mapping of categories to their numeric labels\n",
        "label_mapping = dict(enumerate(label_encoder.classes_))\n",
        "\n",
        "# Print the mapping\n",
        "for num, label in label_mapping.items():\n",
        "    print(f\"Numeric Label: {num} -> Original Category: {label}\")"
      ],
      "metadata": {
        "id": "RQ7GJImIC2yE",
        "outputId": "e91d9a4f-218f-4f30-8c05-f813efdb294d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric Label: 0 -> Original Category: Aid\n",
            "Numeric Label: 1 -> Original Category: Conditions\n",
            "Numeric Label: 2 -> Original Category: Migration\n",
            "Numeric Label: 3 -> Original Category: Policy\n"
          ]
        }
      ]
    }
  ]
}